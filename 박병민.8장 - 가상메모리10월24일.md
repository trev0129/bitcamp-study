# 운영체제와 정보기술의 원리 - 8장 가상메모리

운영체제는 CPU에서 당장 수행해야 할 부분만 메모리에 올려놓고 나머지는 디스크의 스왑영역에 내려놓았다가 다시 필요해지면 메모리에 올라간 부분과 교체하는 방식을 사용함. 이와같은 방법으로 프로그램 입장에서 메모리 크기 제약을 신경쓸 필요가 없어지며, 나아가 운영체제는 프로그램이 자기 자신만의 메모리를 사용하는 것처럼 가정해 프로그램하는 것을 지원함.
프로그램은 0번지부터 시작하는 자기 자신만의 메모리 주소 공간을 가정하는데, 이러한 메모리 공간을 가상 메모리(virtual memory) 라고 함. 프로세스마다 각각 0번지부터의 주소 공간을 가지게 되며, 일부는 물리적 메모리에 적재되고 일부는 스왑영역에 존재함.
프로세스의 주소 공간을 메모리로 적재하는 단위에 따라 요구 페이징 방식과 요구 세그먼테이션 방식으로 구현될 수 있음. 

# 1. 요구 페이징(demand paging)
프로그램 실행 시 당장 사용될 페이지만 올리고 나머지는 디스크의 스왑영역에 존재하는 방식. 메모리 사용량을 줄이고 입출력 오버헤드를 줄이며 응답시간을 단축시킬 수 있음. 또한 사용될 혹은 CPU의 요청이 들어온 페이지만 올리기 때문에 프로그램이 물리적 용량의 제약을 벗어살 수 있음.
요구페이징에선 유효-무효비트를 두어 각 페이지가 메모리에 존재하는지 표시하며, 페이지 테이블의 각 항목별로 저장됨. 무효인 경우가 메모리에 없는 경우를 의미할 수도 있지만 그 페이지가 속한 주소 영역을 프로세스가 사용하지 않는 경우도 있음. 
CPU가 참조하려는 페이지가 메모리에 없어 무효로 세팅되어 있는 경우를 '페이지 부재(page fault)'가 일었나고 함.


## 1) 요구 페이징의 페이지 부재 처리
CPU가 무효 페이지에 접근하면 주소 변환 담당 하드웨어인 MMU가 페이지 부재 트랩(page fault trap)을 발생시킴. 커널모드로 전환되어 운영체제의 페이지 부재 처리루틴(page fault handler)이 호출되어 페이지 부재를 처리함.
부재 상태의 페이지를 메모리에 적재하기에 앞서 운영체제는 해당 페이지에 대한 접근이 적법한지를 먼저 체크함. 사용되지 않는 주소 영역에 속한 페이지에 접근 혹은 해당 페이지의 접근 권한 위반(protection violation)을 했을 경우 해당 프로세스 종료함.
해당 페이지 접근이 적법할 경우 물리적 메모리에 비어있는 프레임을 할당 받아 읽어옴. 비어 있는 프레임이 없다면 스왑아웃 시킴. 요청 페이지를 디스크에서 메모리로 올리기 까지 오랜 시간이 걸리고, 페이지 부재를 발생시킨 프로세스는 봉쇄 상태가 됨. CPU 레지스터 상태 및 프로그램 카운터값을 PCB에 저장함. 입출력 완료 후 인터럽트가 발생하면 유효로 변경 후 프로세스를 준비 큐로 이동함. 할당받을 경우 PCB에 저장한 값을 복원시켜 명령 재개함.

## 2) 요구 페이징의 성능
성능에 가장 큰 영향을 미치는 요소는 페이지 부재의 발생 빈도임. 페이지 부재가 많이 일어나면 많은 오버헤드가 필요함. 디스크 입출력과 각종 오버헤드가 포함되어 시간이 오래 걸리기 때문에 유효 접근시간이 짧을수록 요구 페이징 기법의 성능이 향상됨.

# 2. 페이지 교체
페이지 부재 발생 시 요청 페이지를 메모리로 읽어올 때 물리적 메모리에 빈 프레임이 존재하지 않으면 메모리에 올라와 있는 페이지중 하나를 스왑아웃 시켜 공간을 확보하는 작업을 페이지 교체(page replacement)라 함.
어떤 페이지를 쫒아낼 지 결정하는 알고리즘을 교체 알고리즘(repalcement algorithm)이라 하는데 페이지 부재율을 최소화 하는 목표를 가짐.
페이지 교체 알고리즘의 성능은 주어진 페이지 참조열(page reference string)에 대해 페이지 부재율을 계산함으로써 평가함. 페이지 참조열은 참조되는 페이지들의 번호를 시간 순서에 따라 나열한 것으로, 해당 번호의 페이지가 이미 올라와 있으면 메모리에서 적중(hit)되었다 하고 없는 경우 페이지 부재가 발생했다고 말함.

## 1) 최적 페이지 교체
페이지 교체 시 물리적 메모리에 존재하는 페이지 중 가장 먼 미래에 참조될 페이지를 쫒아네는 최적의 알고리즘을 빌레디의 최적 알고리즘(Belady's optimal algorithm) 혹은 MIN, OPT라고 함.
이 알고리즘은은 미래에 어떤 페이지가 어떤 순서로 참조될 지 알고 있다는 전제하에 알고리즘을 운영하므로 실제 사용 가능한 알고리즘이 아닌 오프라인 알고리즘이라 부름. 이 알고리즘은 다른 알고리즘의 성능에 대한 상한선(upper bound)를 제공해 새로운 알고리즘을 설계했을 때, 빌레이의 최적 알고리즘과 유사하다면 성능이 좋다는 것.

## 2) 선입선출 알고리즘
선입선출 알고리즘은 페이지 교체 시 물리적 메모리에 가장 먼저 올라온 페이지를 우선적으로 내쫒음. 페이지 향후 참조 가능성을 따지지 않기 때문에 비효율적인 상황이 발생할 수 있음.
물리적 메모리의 공간이 늘어났음에도 오히려 페이지의 부재가 늘어나는 상황을 FIFO의 이상 현상(FIFO anomaly)라고 부름. LRU 알고리즘에선 이와 같은 현상이 발생하지 않음.

## 3) LRU 알고리즘(Least Recently Used)
메모리 페이지의 참조 성향 중 중요한 한 가지 성질로 시간지역성(temporal loclity)가 있음. 이 성질은 최근에 참조된 페이지가 가까운 미래에 다시 참조될 가능성이 높은 성질을 말함. LRU 알고리즘은 이를 활용해 페이지 교체 시 가장 오래전에 참조가 이루어진 페이지를 쫒아냄. 즉 마지막 참조 시점이 가장 오래된 페이지를 교체하는 것.

## 4) LFU 알고리즘(Least Frequently Used)
LFU 알고리즘은 페이지의 참조 횟수로 교체시킬 페이지를 결정함. 물리적 메모리 내의 페이지 중 과거 참조 횟수(reference count)가 가장 적었던 페이지를 쫒아내는 것. 여러 개일 경우 임의로 한 개를 선택함. 성능향상을 위해선 최저 참조 횟수 페이지 중 상대적으로 오래전에 참조된 페이지를 쫒아내는 것이 효율적임.
참조횟수를 계산하는 방식에 따라 Incache-LFU와 Perfect-LFU의 서로 다른 방식으로 구현할 수 있음.
Incache-LFU는 물리적 메모리에 올라온 후부터 카운트 하는 방식으로 쫒겨난 후 다시 올라오면 1부터 새로 시작함.
Perfect-LFU는 그 페이지의 과거 총 참조 횟수를 카운트 함. 더 정확히 카운트 할 수 있으나 모든 기록을 보관해야 하므로 오버헤드가 상대적으로 더 크다고 할수 있음.
LFU 는 LRU 보다 오랜 시간 동안의 참조 기록을 반영할 수 있는 장점이 있으나 LFU는 시간에 따른 페이지 참조의 변화를 반영하지 못하고 LRU보다 구현이 복잡한 단점이 있음.

## 5) 클럭 알고리즘(Clock algorithm)
LRU와 LFU 방식은 소프트웨어적으로 유지하고 비교하므로 알고리즘 운영에 시간적 오버헤드가 발생함. 클럭 알고리즘은 하드웨어적인 지원으로 운영 오버헤드를 줄임. LRU를 근사(approximation)시킨 알고리즘으로 NUR(Not Used Recently) 또는 NRU(Not Recently Used) 알고리즘으로도 불림.
오랫동안 참조되지 않은 페이지 중 하나를 교체함. 최근에 참조되지 않은 페이지를 선정하는 것은 LRU와 유사하나 굧되는 페이지의 참조 시점이 가장 오래되었다는 것은 보장하지 못함. 그러나 하드웨어적인 지원으로 동작하기 때문에 LRU에 비해 페이지의 관리가 훨씬 빠르고 효율적으로 이루어짐. 대부분의 시스템이 클럭 알고리즘을 선택함.
교체할 페이지를 선정하기 위해 페이지 프레임들의 참조비트(reference bit)를 순차적으로 조사함. 참조비트는 각 프레임마다 하나씩 존재하며 그 프레임 내의 페이지가 참조될 때 하드웨어에 의해 1로 자동 세팅됨. 여기서 클럭 알고리즘은 1인 페이지는 0으로 바꾼 후 그냥 지나가고 0인 페이지는 교체함.
시곗바늘이 한 바퀴 도는 데 소요되는 시간만큼 페이지를 메모리에 유지시켜둠으로써 부재율을 줄이도록 설계되어 2차 기회 알고리즘(second chance algorithm)이라고 부름.

# 3. 페이지 프레임의 할당
프로세스 여러 개가 동시에 수행되는 상황에서 각 프로세스의 메모리 공간 할당정도를 결정해야 함. 기본적인 할당 할고리즘(allocation algorithm)은 총 세 가지로 나누어 볼 수 있음.
첫 번째 방법은 모든 프로세스에게 페이지 프레임을 균일하게 할당하는 균등할당(equal allocation), 두 번째 방법은 프로세스의 크기에 비례해 할당하는 비례할당(proportional allocation), 세 번째 방식은 프로세스의 우선 순위에 따라 다르게 할당하는 우선순위 할당(priority allocation)방식이 있음.
CPU에서 명령을 실행할 때 일반적으로 여러 페이지를 동시에 참조하게 됨. 명령을 실행할 때 프로세스의 주소 공간 중 코드, 데이터, 스택 등 각기 다른 영역을 참조하기 때문임. 정상적으로 수행하기 위해선 일정 수준 이상의 페이지 프레임을 각 프로세스에 할당해야 함.
또한 반복문(loop)을 실행중인 프로세스의 경우 반복문을 구성하는 페이지를 한꺼번에 메모리에 올려 놓는 것이 유리함. 
이와 같이 종합적인 상황을 고려해서 각 프로세스에 할당하는페이지 프레임의 수를 결정할 필요가 있음.

# 4. 잔역교체와 지역교체
교체 페이지 선정 시, 교체 대상이 될 프레임의 범위를 어떻게 정할지에 따라 전역교체(global replacement)와 지역교체(local replacement)로 구분함.
전역교체 방법은 모든 페이지 프레임이 교체 대상이 될 수 있는 방법이며, 지역교체 방법은 현재 수행 중인 프로세스에게 할당된 프레임 내에서만 교체 대상을 선정할 수 있는 방법임.
지역교체 방법은 프로세스마다 페이지 프레임을 미리 할당하는 것을 전제로 하며, 전역교체 방법은 프로세스마다 메모리를 할당하지 않고 전체 메모리를 각 프로세스가 공유해서 사용하고 교체 알고리즘을 근거해서 할당되는 메모리의 양이 가변적으로 변하는 방법임.


# 5. 스레싱(Thrashing)
프로세스가 원활하게 수행되기 위해 일정 수준 이상의 페이지 프레임을 할당 받아야 함. 집중적으로 참조되는 페이지들의 집합을 메모리에 한꺼번에 적재하지 못하면 페이지 부재율(page fault rate)이 크게 상승해 CPU 이용률(CPU utilzation)이 급격히 떨어질 수 있음. 이와 같은 현상을 스레싱이라 부름.
운영체제는 CPU 이용률이 낮으면 메모리에 올라와 있는 프로세스의 수가 적기 때문이라고 판단함. 준비 큐에 프로세스가 하나라도 있으면 CPU는 프로세스를 실행하므로 쉬지 않는데, CPU 이용률이 낮다는 건 준비 큐가 비는 경우가 발생한다는 것임. 메모리에 올라온 프로세스의 수가 적어 프로세스 모두가 I/O작업을 함으로써 비는 경우가 발생했다 보고 운영체제가 프로세스의 수를 늘리게 된됨.
메모리에 동시에 올라가 있는 프로세스의 수를 다중 프로그래밍의 정도(Multi-programming Degree: MPD)라 부름. 요약하면, CPU 이용률이 낮을 경우 운영체제는 MPD를 높임.
MPD가 과도하게 높아지면 최소한의 페이지 프레임도 할당받지 못하는 상태가 되어 페이지 부재가 빈번히 발생함. 페이지 부재가 발생하면 디스크 I/O작업을 부산하므로 문맥교환을 통해 다른 프로세스에게 CPU 이양됨. 이양 받은 프로세스도 메모리의 양이 지나치게 적으면 페이지 부재가 발생해 모든 프로세스가 페이지 부재를 발생시킴.
시스템은 페이지 부재를 처리하느라 분주하고 CPU 이용률이 떨어지는데 운영체제는 메모리에 올라온 프로세스가 적다 판단해 MPD를 높이려 다른 프로세스를 추가하고, 프로세스당 할당 프레임은 더욱 감소하며 페이지 부재는 더 빈번해짐.
이 경우 프로세스들은 서로의 페이지를 교체하며 스왑 인과 스왑 아웃이 지속적으로 발생하고 CPU는 대부분의 시간에 일을 하지 않게 됨. 이러한 상황을 스레싱이라 부름.
MPD를 적절히 조절해 CPU 이용률을 높이는 동시에 스레싱 발생을 방지하는 방법에 워킹셋 알고리즘과 페이지 부재 빈도 알고리즘이 있음.

## 1) 워킹셋 알고리즘(Working-Set Algorithm)
프로세스는 일정 시간 동안 특정 주소 영역을 집중적으로 참좌는 경향이 있는데 이렇게 집중적으로 참조되는 페이지들의 집합을 지역석 집합(locality set)이라 함. 워킹셋 알고리즘은 지역성 집합이 메모리에 동시에 올라갈 수 있도록 보장하는 메모리 관리 알고리즘을 뜻함.
프로세스가 일정 시간 동안 원활히 수행되기 위해 한꺼번에 메모리에 올라와 있어야 하는 페이지들의 집합을 워킹셋이라 정의하고, 프로세스의 워킹셋을 구성하는 페이지들이 한꺼번에 올라갈 수 있는 경우에만 그 프로세스에게 메로리를 할당함.
그렇지 않은 경우 프로세스에게 할당된페이지를 모두 반납시킨 후 그 프로세스의 주소 공간 전체를 스왑아웃 시킴.
한꺼번에 메모리에 올라가야 할 페이지들의 집합을 결정하기 위해 워킹셋 윈도우(working-set window)를 사용함.
워킹셋 알고리즘은 메모리에 올라온 프로세스들의 워킹셋 크기의 합이 프레임의 수 보다 클 경우 일부 프로세스를 스왑 아웃시켜서 남은프로세스의 워킹셋이 메모리에 모두 올라가는 것을 보장함. 반면 프로레스들의 워킹셋을 모두 할당한 수에도 프레임이 남을 경우 스왑아웃되었던 프로세스를 다시 메모리에 올려 워킹셋을 할당함으로써 MPD를 증가시키는 방식으로 CPU 이용률을 높이며 MPD를 적절이 조정함.
윈도우의 크기가 너무 작으면 지역성 집합을 모두 수용하지 못할 수 있고, 너무 크면 여러 규모의 지역성 집합을 수용하지만 MPD가 감소해 CPU 이용률이 낮아질 수 있음. 시스템 성능 샹항을 위해 프로세스들의 지역성 집합을 효과적으로 탐지할 수 있는 윈도우 크기를 결정하는 것이 중요함.
워킹셋 알고리즘은 프로세스가 메모리를 많이 필요로 할 때에는 많이 할당하고 적게 필요로 할 때는 적게 할당하는 일종의 동적인 프레임 할당 기능까지 수행한다고 할 수 있음.


## 2) 페이지 부재 빈도 알고리즘(page-fault frequency Scheme: PFF scheme)
프로세스의 페이지 부재율을 주기적으로 조사하고 이 값에 근거해 각 프로세스에 할당할 메모리 양을 동적으로 조절함. 
페이지 부재율이 시스템이 미리 정한 상한값(upper bound)을 넘게 되면 해당 프로세스에 할당된 프레임 수가 부족하다고 판단하여 프로세스에게 프레임을 추가로 더 할당함. 이때 추가로 할당할 빈 프레임이 없다면 일부 프로세스를 스왑 아웃시켜 메모리에 올라간 프로세스이 수를 조절함.
페이지 부재율이 하한값(lower bound) 이하로 떨어지면 해당 프로세스에게  필요 이상으로 많은 프레임이 할당된 것으로 간주해 할당된 프레임 수를 줄임. 메모리 내에 존재하는 모든 프로세스에 필요한 프레임을 다 할당한 후에도 프레임이 남는 경우 스왑아웃되었던 프로세스에게 프레임을 할당함으로써 MPD를 높임.








